%!TEX encoding = UTF-8 Unicode

\documentclass[a4paper]{article}

\usepackage{INTERSPEECH_v2}

\usepackage[T1]{fontenc} % output - specifies encoding used in fonts; needs full LaTeX distribution to produce good-looking output
\usepackage[utf8]{inputenc} % input - type accented characters directly from keyboard
\usepackage[english]{babel} % internationalization - hyphenation, typographic rules for one or more languages

\usepackage[nolist]{acronym}
\usepackage{hyperref}

\title{Interactive Learning of Human Gestures, Language and Affordances}
\name{Giovanni~Saponaro$^1$, Giampiero~Salvi$^2$, Lorenzo~Jamone$^{3,1}$, Alexandre~Bernardino$^1$}
\address{
  $^1$Institute for Systems and Robotics\\Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal\\
  $^2$KTH Royal Institute of Technology, Stockholm, Sweden\\
  $^3$ARQ~(Advanced Robotics at Queen Mary)\\School of Electronic Engineering and Computer Science, Queen Mary University of London, UK}
\email{gsaponaro@isr.tecnico.ulisboa.pt, giampi@kth.se, l.jamone@qmul.ac.uk, alex@isr.tecnico.ulisboa.pt}

% custom commands
\newcommand{\eg}{e.\,g.}
\newcommand{\ie}{i.\,e.}

% examples and useful stuff from INTERSPEECH template

% \begin{table}
%   \caption{This is an example of a table}
%   \label{tab:example}
%   \centering
%   \begin{tabular}{ r@{}l  r }
%     \toprule
%     \multicolumn{2}{c}{\textbf{Ratio}} &
%                                          \multicolumn{1}{c}{\textbf{Decibels}} \\
%     \midrule
%     $1$                       & $/10$ & $-20$~~~             \\
%     $1$                       & $/1$  & $0$~~~               \\
%     $2$                       & $/1$  & $\approx 6$~~~       \\
%     $3.16$                    & $/1$  & $10$~~~              \\
%     $10$                      & $/1$  & $20$~~~              \\
%     $100$                     & $/1$  & $40$~~~              \\
%     $1000$                    & $/1$  & $60$~~~              \\
%     \bottomrule
%   \end{tabular}
% \end{table}

%\begin{figure}
%  \centering
%  \includegraphics[width=\linewidth]{figure.pdf}
%  \caption{Schematic diagram of speech production.}
%  \label{fig:speech_production}
%\end{figure}

% For technical reasons, the proceedings editor will strip all active links from the papers during processing. Hyperlinks can be included in your paper, if written in full, e.\,g.\ ``http://www.foo.com/index.html''. The link text must be all black.
% Please make sure that they present no problems in printing to paper.

% list of acronyms
\begin{acronym}
\acro{HMM}{Hidden Markov Model}
\end{acronym}

\begin{document}

\maketitle
%
\begin{abstract} % max 200 words
  blah
\end{abstract}
\noindent\textbf{Index Terms}: cognitive robotics, gesture recognition, object affordances

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

In neuroscience research, visuomotor neurons~(\ie, neurons that are activated by visual stimuli) have been a subject of ample study~\cite{rizzolatti:2001:nrn}. Mirror neurons are one class of such neurons that responds to action and object interaction, both when the agent acts and when it observes the same action performed by others, hence the name ``mirror''.

This work is framed within the theory of mirror neurons. We show that a cognitive robot can first acquire knowledge by sensing and self-exploring its surrounding environment~(\eg, by interacting with available objects and building up an affordance representation of the interactions and their outcomes) and, then, the robot is capable of generalizing its acquired knowledge while observing another agent~(\eg, a human person) performing similar physical actions to the ones performed during robot training.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}

blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Approach}

We follow the method adopted in the evaluation part of~\cite{salvi:2012:smcb}, however, instead of assuming that the action identities are known to the robot agent, we estimate them by observing an external agent and applying statistical inference methods~(\acp{HMM}).

% TO TRANSLATE
% a) Per esempio, si potrebbe fare la stima delle azioni e stimare la forma
% dell'oggetto basandoci sull'azione stimata e sull'effetto ottenuto,
% oppure b) viceversa. Cioè, un obbiettivo dello studio potrebbe essere di
% dimostrare che c) quello che ha imparato il robot in soggettiva
% (conoscendo per certo l'identità delle azioni), può essere applicato
% anche nell'osservazione di un nuovo agente (l'uomo), se le azioni
% possono essere stimate con le tue HMM. Non so se l'idea è chiara.
%
% Il
% motivo per il quale l'obbiettivo può sembrare un po' vago è che le
% reti bayesiane sono molto flessibili e si possono usare per obbiettivi
% diversi, per cui abbiamo molta libertà di scelta sull'esperimento da
% effettuare.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}

blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work}

blah

extra refs:

http://www.nature.com/neuro/journal/v7/n1/abs/nn1168.html

http://journals.sagepub.com/doi/10.1111/1467-9280.00387

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Acknowledgements}
%
% blah

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%The reference format is the standard IEEE one. References should be numbered in order of appearance
%\newpage
%\balance
\nocite{*} % TODO remove this when article is finished
\bibliographystyle{IEEEtran}
%\bibliographystyle{IEEEtran/bibtex/IEEEtran}
\bibliography{glu2017_bibliography}

\end{document}
