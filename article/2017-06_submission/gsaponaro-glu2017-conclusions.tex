%!TEX encoding = UTF-8 Unicode

\section{Conclusions and Future Work}

Within the scope of cognitive robots that operate in unstructured environments, we have discussed a model that combines word affordance learning with body gesture recognition. We have analyzed theoretical and neuroscientific aspects of such an approach, based on the intuition that a robot can generalize its previously-acquired knowledge of the world~(objects, actions, effects, verbal descriptions) to the cases when it observes a human agent performing familiar actions in a shared \hr{} environment. We have shown promising results that indicate that a robot's ability to predict the future can benefit from incorporate the knowledge of a partner's action, facilitating scene interpretation and, as a result, teamwork.

In terms of future work, there are several avenues to explore. The main ones are (i)~the implementation of a fully probabilistic fusion between the affordance and the gesture components~(EXPLAIN BETTER, THE IDEA IS TO USE SOFT DECISION RATHER THAN HARD); (ii)~to run quantitative tests on larger corpora of \hr{} data.
